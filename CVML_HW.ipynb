{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVML_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GEjhEKiGZuk1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWFVscRmZmVT",
        "colab_type": "text"
      },
      "source": [
        "# Homework\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TesXqCt7coAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update torch, torchvision and numpy\n",
        "!pip install -U torch torchvision numpy opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ynvKXBOwGB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install homework repository\n",
        "!git clone https://github.com/szykry/CVML_HW.git\n",
        "\n",
        "# Set repo as root folder\n",
        "import os\n",
        "name = \"/content/CVML_HW/\"\n",
        "os.chdir(name)\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdmC5juWvsMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Homework dataset\n",
        "!wget http://deeplearning.iit.bme.hu/CVS/HW.zip\n",
        "!unzip -qq HW.zip\n",
        "!rm HW.zip\n",
        "\n",
        "# Traffic Sign Classification set\n",
        "!wget http://deeplearning.iit.bme.hu/CVS/trafficSignsHW.zip\n",
        "!unzip -qq trafficSignsHW.zip\n",
        "!rm trafficSignsHW.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OKxWDeqqwco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq pics.zip\n",
        "!rm pics.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7X5oEPzqDGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"./pics\"):\n",
        "  for filename in filenames:\n",
        "    print(filename)\n",
        "    a=cv2.imread(\"/content/CVML_HW/pics/\"+filename)\n",
        "    a=cv2.cvtColor(a,cv2.COLOR_BGR2RGB)\n",
        "    plt.figure()\n",
        "    plt.imshow(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEjhEKiGZuk1",
        "colab_type": "text"
      },
      "source": [
        "# Tradition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvzlqdEVKl39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OpenCV\n",
        "import cv2\n",
        "\n",
        "#Numpy - numeric library\n",
        "import numpy as np\n",
        "\n",
        "#Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#This way it doesn't try to open a window un the GUI - works in python notebook\n",
        "%matplotlib inline\n",
        "\n",
        "def minMaxLoc(img):\n",
        "  Xmin = 999;\n",
        "  Xmax = 0;\n",
        "  Ymin = 999;\n",
        "  Ymax = 0;\n",
        "  \n",
        "  for i in range(img.shape[0]):\n",
        "    sor =img[i,:]\n",
        "    mean=np.count_nonzero(sor)\n",
        "    if ((Ymin == 999) & (mean > 0)):\n",
        "      Ymin=i\n",
        "    if ( mean > 0):\n",
        "      Ymax = i\n",
        "\n",
        "  for i in range(img.shape[1]):\n",
        "    oszlop =img[:,i]\n",
        "    mean=np.count_nonzero(oszlop)\n",
        "    if ((Xmin == 999) & (mean > 0)):\n",
        "      Xmin=i\n",
        "    if ( mean > 0):\n",
        "      Xmax = i\n",
        "\n",
        "  return Xmin,Xmax,Ymin,Ymax\n",
        "\n",
        "def watershed(edges,img,debug=False):\n",
        "  kernel = np.ones((3,3),np.uint8)\n",
        "  #widen edges to make them touch\n",
        "  edges = cv2.dilate(edges, kernel,iterations=1)\n",
        "\n",
        "  ret, thresh = cv2.threshold(edges,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "  if debug:\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.imshow(thresh,cmap='gray')\n",
        "\n",
        "  sure_fg = cv2.erode(thresh,kernel,iterations=1)\n",
        "  sure_bg = cv2.dilate(thresh,kernel,iterations=1)\n",
        "\n",
        "  # Uncertain region(borders)\n",
        "  unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "\n",
        "  if debug:\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.imshow(sure_fg,cmap='gray')\n",
        "\n",
        "  # Label separate foreground pathes\n",
        "  ret, markers = cv2.connectedComponents(sure_fg)\n",
        "      \n",
        "  # Add one to all labels so that sure background is not 0, but 1\n",
        "  markers = markers+1\n",
        "  # Now, mark the region of unknown with zero\n",
        "  markers[unknown==255] = 0\n",
        "\n",
        "  if debug:\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.imshow(markers)\n",
        "    \n",
        "  # Runwatershed\n",
        "  markers = cv2.watershed(img,markers)\n",
        "  if debug:\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(markers)\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(img)\n",
        "\n",
        "  return markers\n",
        "\n",
        "def depth_segmenter(debug=False):\n",
        "  # Read images\n",
        "  img = cv2.imread(\"../HW/g3/rgb/250.jpg\")\n",
        "  depth = cv2.imread(\"../HW/g3/depth/250.png\", -1)\n",
        "  depth2 = cv2.imread(\"../HW/g3/depth/250.png\")\n",
        "\n",
        "  sor =depth[0,:]\n",
        "  legelsoAtlag=np.true_divide(sor.sum(),np.count_nonzero(sor))\n",
        "\n",
        "  #hatsoMaszk=cv2.inRange(depth, legelsoAtlag*0.9, np.amax(depth))\n",
        "  hatsoMaszk =  np.zeros((480,640)).astype(\"uint8\")\n",
        "  hatsoMaszk[depth<legelsoAtlag*0.7]=[1]\n",
        "\n",
        "  if debug:\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(hatsoMaszk,cmap='gray')\n",
        "\n",
        "  # convert to RGB\n",
        "  img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  img_hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
        "\n",
        "  lower_range = np.array([90,0,0])\n",
        "  upper_range = np.array([120,255,220])\n",
        "\n",
        "  maszk=cv2.inRange(img_hsv, lower_range, upper_range)\n",
        "\n",
        "  maszkNegative = cv2.bitwise_not(maszk)\n",
        "  \n",
        "  if debug:\n",
        "    out = cv2.bitwise_and(img_hsv,img_hsv,mask = maszkNegative)\n",
        "    plotolni = cv2.cvtColor(out, cv2.COLOR_HSV2RGB)\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(plotolni,cmap='gray')\n",
        "\n",
        "  hue_channel = img_hsv[:,:,0]\n",
        "  avg_hue = np.average(hue_channel)\n",
        "  asdasd, hue_channel_segment = cv2.threshold(hue_channel,avg_hue,255,cv2.THRESH_BINARY)\n",
        "  kernel = np.ones((5,5),np.uint8)\n",
        "  maszkDilation = cv2.erode(hue_channel_segment,kernel,iterations = 2)\n",
        "\n",
        "  maszkDilation = cv2.bitwise_not(maszkDilation)\n",
        "  maszkNegative = cv2.bitwise_and(maszkDilation,maszkDilation,mask = maszkNegative)\n",
        "  maszkNegative = cv2.bitwise_and(maszkNegative,maszkNegative,mask = hatsoMaszk)\n",
        "  \n",
        "  if debug:\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(maszkNegative,cmap='gray')\n",
        "\n",
        "  # calculate foreground\n",
        "  for i in range(depth.shape[0]):\n",
        "    sor =depth[i,:]\n",
        "    mean=np.true_divide(sor.sum(),np.count_nonzero(sor))\n",
        "    sor[sor>mean-10]=0\n",
        "\n",
        "  # for some reason doesn't work without this\n",
        "  depth2[depth==0]=0\n",
        "  img_rgb = np.where(depth2 != 0, img_rgb, [0,0,0])\n",
        "\n",
        "  # Figure with subplots\n",
        "  if debug:\n",
        "    plt.figure(figsize=(30,30))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img_rgb) \n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(depth,cmap='gray')\n",
        "\n",
        "  # convert to uint8 from uint16\n",
        "  cv2.normalize(depth, depth, 0, 255, cv2.NORM_MINMAX)\n",
        "  depth=depth.astype('uint8')\n",
        "  depth_8 = cv2.cvtColor(depth, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "  # get edges\n",
        "  edges = cv2.Canny(depth_8,50,120)\n",
        "  markers = watershed(edges,img,debug=True)\n",
        "\n",
        "  ####\n",
        "  img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  for i in np.unique(markers):\n",
        "    if i<2 :\n",
        "      continue\n",
        "\n",
        "    imgcopy=img.copy()\n",
        "    imgcopy[markers!=i]=[0,0,0]  \n",
        "    xmin,xmax,ymin,ymax = minMaxLoc(imgcopy)\n",
        "\n",
        "    if ((xmax-xmin > 500) & (ymax-ymin > 350)):\n",
        "      continue\n",
        "    \n",
        "    imgcopy = cv2.bitwise_and(imgcopy,imgcopy,mask = maszkNegative)\n",
        "\n",
        "    if np.count_nonzero(imgcopy)<3600:\n",
        "      continue\n",
        "\n",
        "    #if np.var(np.nonzero(cv2.cvtColor(imgcopy,cv2.COLOR_RGB2HSV)[:,:,0]))<4200:\n",
        "    #  continue\n",
        "    if debug:\n",
        "      plt.figure(figsize=(10,10))\n",
        "      plt.imshow(imgcopy)\n",
        "      print(str(i)+\":\"+str(np.var(np.nonzero(cv2.cvtColor(imgcopy,cv2.COLOR_RGB2HSV)[:,:,0])))+\"........\\t\"+str(np.count_nonzero(imgcopy))+\"minmax:\"+str(xmin)+\" \"+str(xmax)+\" \"+str(ymin)+\" \"+str(ymax))\n",
        "\n",
        "  if debug:\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(cv2.imread(\"../HW/g1/depth/1.png\", -1),cmap='gray')\n",
        "\n",
        "depth_segmenter(debug=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gxeCxDPazgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the first images\n",
        "colors = [(0,0,255),(255,0,255),(0,255,0)]\n",
        "\n",
        "def drawBBs(BBs, img):\n",
        "    img = cv2.resize(img, (1280, 960))\n",
        "    for BB in BBs:\n",
        "        u = BB[0]*2\n",
        "        v = BB[1]*2\n",
        "        w = BB[2]*2\n",
        "        h = BB[3]*2\n",
        "        c = BB[4]\n",
        "        sc = BB[5]\n",
        "        x = BB[6]\n",
        "        y = BB[7]\n",
        "        z = BB[8]\n",
        "        s = (u - w // 2, v - h // 2)\n",
        "        e = (u + w // 2, v + h // 2)\n",
        "        cv2.rectangle(img, s, e, colors[c], 1)\n",
        "        tl = (s[0], s[1]+15)\n",
        "        bl = (s[0], e[1]-5)\n",
        "        cv2.putText(img,subclassNames[c][sc],tl,cv2.FONT_HERSHEY_COMPLEX_SMALL,0.75,colors[c])\n",
        "        coords = \"(%.2f, %.2f, %.2f)\" % (x,y,z)\n",
        "        cv2.putText(img,coords,bl,cv2.FONT_HERSHEY_COMPLEX_SMALL,0.65,colors[c])\n",
        "    \n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL7_ps4RZ0rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all subfolders in a directory\n",
        "import os\n",
        "myFolderList = [f.path for f in os.scandir(path) if f.is_dir()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vj_xm0najIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all files with extension in a directory\n",
        "import glob\n",
        "import re\n",
        " \n",
        "def sorted_nicely( l ):\n",
        "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\"\n",
        "    convert = lambda text: int(text) if text.isdigit() else text\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
        "    return sorted(l, key = alphanum_key)\n",
        " \n",
        "names = sorted_nicely(glob.glob1(path, \"*.extension\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYQvzVjJaulE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class names\n",
        "classNames = ['traffic sign', 'vehicle', 'cactus']\n",
        "subclassNames = [\n",
        "    ['Bump', 'Bumpy road', 'Bus stop', 'Children', 'Crossing (blue)', 'Crossing (red)', 'Cyclists',\n",
        "     'Danger (other)', 'Dangerous left turn', 'Dangerous right turn', 'Give way', 'Go ahead', 'Go ahead or left',\n",
        "     'Go ahead or right', 'Go around either way', 'Go around left', 'Go around right', 'Intersection', 'Limit 100',\n",
        "     'Limit 120', 'Limit 20', 'Limit 30', 'Limit 50', 'Limit 60', 'Limit 70', 'Limit 80', 'Limit 80 over',\n",
        "     'Limit over', 'Main road', 'Main road over', 'Multiple dangerous turns', 'Narrow road (left)',\n",
        "     'Narrow road (right)', 'No entry', 'No entry (both directions)', 'No entry (truck)', 'No stopping', 'No takeover',\n",
        "     'No takeover (truck)', 'No takeover (truck) end', 'No takeover end', 'No waiting', 'One way road',\n",
        "     'Parking', 'Road works', 'Roundabout', 'Slippery road', 'Stop', 'Traffic light', 'Train crossing',\n",
        "     'Train crossing (no barrier)', 'Wild animals', 'X - Priority', 'X - Turn left', 'X - Turn right'],\n",
        "    ['SUV','truck','plane'],\n",
        "    ['happy','sad','angry','evil']\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjRbWeZbkppp",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAPuGpoEdM74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use --help to list the available arguments\n",
        "# !python train.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXNe5h1-kszB",
        "colab_type": "code",
        "outputId": "aecfda3d-f582-4983-82ab-209dc2ceb2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import optim\n",
        "from torchvision import transforms, datasets, get_image_backend\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "haveCuda = torch.cuda.is_available()\n",
        "numEpoch = 50\n",
        "batch_size = 64     # train set: 104027, test set: 10418 -> useful batch sizes: 32 or 64\n",
        "num_workers = 4\n",
        "train_dir = './trafficSignsHW/trainFULL'\n",
        "test_dir = './trafficSignsHW/testFULL'\n",
        "targets = ['Bump', 'Bumpy road', 'Bus stop', 'Children', 'Crossing (blue)', 'Crossing (red)', 'Cyclists',\n",
        "           'Danger (other)', 'Dangerous left turn', 'Dangerous right turn', 'Give way', 'Go ahead', 'Go ahead or left',\n",
        "           'Go ahead or right', 'Go around either way', 'Go around left', 'Go around right', 'Intersection', 'Limit 100',\n",
        "           'Limit 120', 'Limit 20', 'Limit 30', 'Limit 50', 'Limit 60', 'Limit 70', 'Limit 80', 'Limit 80 over',\n",
        "           'Limit over', 'Main road', 'Main road over', 'Multiple dangerous turns', 'Narrow road (left)',\n",
        "           'Narrow road (right)', 'No entry', 'No entry (both directions)', 'No entry (truck)', 'No stopping', 'No takeover',\n",
        "           'No takeover (truck)', 'No takeover (truck) end', 'No takeover end', 'No waiting', 'One way road',\n",
        "           'Parking', 'Priority', 'Road works', 'Roundabout', 'Slippery road', 'Stop', 'Traffic light', 'Train crossing',\n",
        "           'Train crossing (no barrier)', 'Turn left', 'Turn right', 'Wild animals'\n",
        "           ]\n",
        "\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "\n",
        "def plotResults():\n",
        "    # X coordinate for plotting\n",
        "    x = np.arange(numEpoch)\n",
        "\n",
        "    plt.figure(figsize=(20,10))\n",
        "\n",
        "    # Train is red, validation is blue\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(x,train_accs,'r')\n",
        "    plt.plot(x,val_accs,'b')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(x,train_losses,'r')\n",
        "    plt.plot(x,val_losses,'b')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def transformData():\n",
        "\n",
        "    transform_val = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),   # random shift\n",
        "        transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3, fill=0),\n",
        "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    return transform, transform_val\n",
        "\n",
        "\n",
        "class Conv(nn.Module):\n",
        "  \n",
        "    def __init__(self, in_channels, channels, k_size=3, stride=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Conv2d(in_channels, channels, k_size, stride=stride, padding=k_size//2, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(channels)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        return self.bn(torch.relu(self.conv(x)))\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, base_channels=16, in_channels=3, num_classes=55):  # base: csatorna növekedéshez, in: RGB\n",
        "        super().__init__()\n",
        "        \n",
        "        # Filters\n",
        "        self.c11 = Conv(in_channels, base_channels)\n",
        "        self.c12 = Conv(base_channels, base_channels)\n",
        "        self.d1  = Conv(base_channels, base_channels*2, stride=2) # Downscale using strided convolution and expand channels\n",
        "        \n",
        "        self.c21 = Conv(base_channels*2, base_channels*2)\n",
        "        self.c22 = Conv(base_channels*2, base_channels*2)\n",
        "        self.d2  = Conv(base_channels*2, base_channels*4, stride=2)\n",
        "        \n",
        "        self.c31 = Conv(base_channels*4, base_channels*4)\n",
        "        self.c32 = Conv(base_channels*4, base_channels*4)\n",
        "        self.d3  = Conv(base_channels*4, base_channels*8, stride=2)\n",
        "        \n",
        "        self.c41 = Conv(base_channels*8, base_channels*8)\n",
        "        self.c42 = Conv(base_channels*8, base_channels*8)\n",
        "        self.d4  = Conv(base_channels*8, base_channels*16, stride=2)\n",
        "        \n",
        "        self.c51 = Conv(base_channels*16, base_channels*16)\n",
        "        self.c52 = Conv(base_channels*16, base_channels*16)\n",
        "        self.d5  = Conv(base_channels*16, base_channels*32, stride=2) \n",
        "\n",
        "        # Input image is 32x32 -> after 5 downscaling the activation map is 1x1\n",
        "        # [batch, ch, h, w]  -> [batch, ch] linearisba, h=1, w=1\n",
        "        # Classifier is a normal 1x1 convolution that produces num_classes class scores\n",
        "        # This layer does not have BatchNorm or ReLU\n",
        "\n",
        "        self.classifier = nn.Conv2d(base_channels*32, num_classes, kernel_size=1)\n",
        "        \n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.d1(self.c12(self.c11(x)))\n",
        "        x = self.d2(self.c22(self.c21(x)))\n",
        "        x = self.d3(self.c32(self.c31(x)))\n",
        "        x = self.d4(self.c42(self.c41(x)))\n",
        "        x = self.d5(self.c52(self.c51(x)))\n",
        "        \n",
        "        return torch.squeeze(self.classifier(x))    # After squeeze is becomes (batch_size x num_classes)\n",
        "\n",
        "\n",
        "def train(epoch, trainLoader):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    bar = display(progress(0, len(trainLoader)), display_id=True)     # Create progress bar\n",
        "\n",
        "    for i, data in enumerate(trainLoader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        if haveCuda:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            running_loss += loss.item()     # Accumulate loss\n",
        "            _, predicted = torch.max(outputs, 1)  # [batch, num_class] -> [batch, 1]\n",
        "            correct += predicted.eq(labels).sum().item() # Count how many of the predictions equal the labels\n",
        "            total += labels.shape[0]   # Accumulate number of total images seen\n",
        "\n",
        "        bar.update(progress(i+1, len(trainLoader)))\n",
        "\n",
        "    tr_loss = running_loss / i\n",
        "    tr_corr = correct / total * 100\n",
        "    print(\"Train epoch %d loss: %.3f correct: %.2f\" % (epoch + 1, running_loss / i, tr_corr))\n",
        "\n",
        "    return tr_loss,tr_corr\n",
        "\n",
        "\n",
        "def val(epoch,testLoader):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    bar = display(progress(0, len(testLoader)), display_id=True)\n",
        "\n",
        "    for i, data in enumerate(testLoader, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "        if haveCuda:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.shape[0]\n",
        "\n",
        "        bar.update(progress(i+1, len(testLoader)))\n",
        "\n",
        "    val_loss = running_loss / i\n",
        "    val_corr = correct / total * 100\n",
        "    print(\"Test epoch %d loss: %.3f correct: %.2f\" % (epoch + 1, running_loss / i, val_corr))\n",
        "\n",
        "    return val_loss,val_corr\n",
        "\n",
        "\n",
        "def testModel():\n",
        "\n",
        "    inputs, labels = next(iter(train_loader))\n",
        "    if haveCuda:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    net = torch.load(\"./model/pyVision_full_tf.pth\")\n",
        "    net.eval()\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    mean = torch.Tensor((0.485, 0.456, 0.406)).unsqueeze(1).unsqueeze(1)\n",
        "    std = torch.Tensor((0.229, 0.224, 0.225)).unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "\n",
        "    f, axarr = plt.subplots(batch_size//8, 8,figsize=(30, 20)) # 64 images\n",
        "\n",
        "    for i,(img,pred) in enumerate(zip(inputs,predicted)):\n",
        "\n",
        "        img_rescaled = img.cpu() * std + mean         # undo the normalization\n",
        "        \n",
        "        name = targets[pred.cpu().item()]\n",
        "        \n",
        "        axarr[i//8,i%8].imshow(img_rescaled.permute(1,2,0))         # Permute dimensions\n",
        "        \n",
        "        axarr[i//8,i%8].set_title(name)\n",
        "        \n",
        "        axarr[i//8,i%8].grid(True)\n",
        "        \n",
        "        axarr[i//8,i%8].set_xticks([])\n",
        "        axarr[i//8,i%8].set_yticks([])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    transform, transform_val = transformData()\n",
        "  \n",
        "    train_dataset = datasets.ImageFolder(train_dir, transform)\n",
        "    test_dataset = datasets.ImageFolder(test_dir, transform_val)\n",
        "                          \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                               shuffle=True,\n",
        "                                               batch_size=batch_size,\n",
        "                                               num_workers=num_workers\n",
        "                                               )\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              num_workers=num_workers\n",
        "                                              )\n",
        "\n",
        "    train_accs = []\n",
        "    train_losses = []\n",
        "    val_accs = []\n",
        "    val_losses = []\n",
        "\n",
        "    best_acc = 0\n",
        "\n",
        "    tfLearning = True\n",
        "\n",
        "    if not tfLearning:\n",
        "        torch.manual_seed(1)  # Set pseudo-random generator seeds to make multiple runs comparable\n",
        "        if haveCuda:\n",
        "            torch.cuda.manual_seed(1)\n",
        "\n",
        "        net = ConvNet()\n",
        "        \n",
        "    else:\n",
        "        net = torch.load(\"./model/pyVision_full_tf.pth\")\n",
        "\n",
        "    if haveCuda:\n",
        "        net = net.cuda()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=1e-1, momentum=0.9, nesterov=True, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,numEpoch,eta_min=1e-2)\n",
        "\n",
        "    for epoch in range(numEpoch):\n",
        "        \n",
        "        loss,acc = train(epoch,train_loader)\n",
        "        train_accs.append(acc)\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        loss,acc = val(epoch,test_loader)\n",
        "        val_accs.append(acc)\n",
        "        val_losses.append(loss)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if not tfLearning:\n",
        "          if acc > best_acc:\n",
        "              print(\"Best Model, Saving\")\n",
        "              best_acc = acc\n",
        "              torch.save(net,\"./model/pyVision_full_tf.pth\")\n",
        "\n",
        "        else:\n",
        "          if acc > 99.5:\n",
        "              print(\"Best Model, Saving\")\n",
        "              best_acc = acc\n",
        "              torch.save(net,\"./model/pyVision_full_tf.pth\")\n",
        "    \n",
        "    # Results\n",
        "    plotResults()\n",
        "\n",
        "    testModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='1638'\n",
              "            max='1638',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            1638\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 1 loss: 0.193 correct: 94.69\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='164'\n",
              "            max='164',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            164\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test epoch 1 loss: 0.075 correct: 97.80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='1638'\n",
              "            max='1638',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            1638\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 2 loss: 0.100 correct: 97.23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='164'\n",
              "            max='164',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            164\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test epoch 2 loss: 0.058 correct: 98.41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='1638'\n",
              "            max='1638',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            1638\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 3 loss: 0.090 correct: 97.53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='164'\n",
              "            max='164',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            164\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test epoch 3 loss: 0.031 correct: 99.23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='1638'\n",
              "            max='1638',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            1638\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 4 loss: 0.091 correct: 97.51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='164'\n",
              "            max='164',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            164\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test epoch 4 loss: 0.063 correct: 98.15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <progress\n",
              "            value='605'\n",
              "            max='1638',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            605\n",
              "        </progress>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvZW3NFuyfB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "\n",
        "def sorted_nicely( l ):\n",
        "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\"\n",
        "    convert = lambda text: int(text) if text.isdigit() else text\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
        "    return sorted(l, key = alphanum_key)\n",
        "\n",
        "\n",
        "myFolderList = [f.path for f in os.scandir('./trafficSignsHW/trainFULL') if f.is_dir()]\n",
        "myFolderList.sort()\n",
        "\n",
        "for folder in myFolderList:\n",
        "  img_paths = sorted_nicely(glob.glob1(folder, \"*.jpg\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKygKrEps-EJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model's parameters\n",
        "net = torch.load(\"./model/pyVision_full_s.pth\")\n",
        "for param_tensor in net.state_dict():\n",
        "    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2O0JKSv22AP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.imread(\"./trafficSignsHW/testFULL/Priority/g1_89_3.1ts.jpg\")\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(img)\n",
        "\n",
        "img = torch.from_numpy(img)\n",
        "img = img.permute(2,0,1)\n",
        "\n",
        "input = torch.zeros(1,3,32,32)\n",
        "input[0] = img\n",
        "\n",
        "if haveCuda:\n",
        "    input = input.cuda()\n",
        "\n",
        "net = torch.load(\"./model/pyVision_full_tf.pth\")\n",
        "net.eval()\n",
        "output = net(input)\n",
        "\n",
        "_, pred = torch.max(output, 0)\n",
        "\n",
        "print(targets[pred.cpu().item()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcT7Oa9_bDsC",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSKQlIOZbWy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (u, v) are the center coordinates of the object's bounding box, while (w, h) are the width and height parameters. All four are expected in pixels @640x480 resolution!\n",
        "# (x, y, z) are the 3D coordinates of the object relative to the camera. They are expected in meters!\n",
        "\n",
        "myObjects = [u, v, w, h, classInd, subClassInd, x, y, z]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3jK8eSMbc2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# poses = np.zeros((12,), dtype=int)  => 3D HC\n",
        "\n",
        "myPred = {\n",
        "    'poses' : [t_11, t12_, t_13, t_14, ..., t_33, t_34],\n",
        "    'objects' : [obj_1, obj_2, ... obj_n]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L78aveEObdj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myAnswers = {\n",
        "    'HW/g1/rgb/1.jpg' : myPred1,\n",
        "    'HW/g1/rgb/123.jpg' : myPred2,\n",
        "    ...\n",
        "    'HW/g4/rgb/95.jpg' : myPredX,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHrm_0jcbIrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from HW.evaluate import evaluate\n",
        "\n",
        "file = open('all_predictions.pickle','rb')\n",
        "predictions = pickle.load(file)\n",
        "\n",
        "evaluate(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}