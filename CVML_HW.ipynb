{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVML_HW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWFVscRmZmVT",
        "colab_type": "text"
      },
      "source": [
        "# Homework\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TesXqCt7coAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update torch, torchvision and numpy\n",
        "!pip install -U torch torchvision numpy opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdmC5juWvsMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Homework dataset\n",
        "!wget http://deeplearning.iit.bme.hu/CVS/HW.zip\n",
        "!unzip -qq HW.zip\n",
        "!rm HW.zip\n",
        "\n",
        "# Traffic Sign Classification set\n",
        "!wget http://deeplearning.iit.bme.hu/CVS/trafficSignsHW.zip\n",
        "!unzip -qq trafficSignsHW.zip\n",
        "!rm trafficSignsHW.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ynvKXBOwGB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install homework repository\n",
        "# !git clone https://github.com/szykry/CVML_HW.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Bypy08dDaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set root folder\n",
        "import os\n",
        "name = \"/content/CVML_HW/\"\n",
        "os.chdir(name)\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWbWDlg-v5oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation\n",
        "from HW.evaluate import evaluate\n",
        "\n",
        "#file = open('HW/annotations.pickle','rb')\n",
        "#predictions = pickle.load(file)\n",
        "\n",
        "evaluate(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEjhEKiGZuk1",
        "colab_type": "text"
      },
      "source": [
        "# Tradition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4HMK6T7KVtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://docs.opencv.org/4.3.0/d1/d1a/namespacecv_1_1cuda.html\n",
        "\n",
        "# Tábla -> hough\n",
        "# szegmentális\n",
        "# cv.threshold\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvzlqdEVKl39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#OpenCV\n",
        "import cv2\n",
        "\n",
        "#Numpy - numeric library\n",
        "import numpy as np\n",
        "\n",
        "#Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#This way it doesn't try to open a window un the GUI - works in python notebook\n",
        "%matplotlib inline\n",
        "\n",
        "minVal = 0.0\n",
        "maxVal = 0.0\n",
        "\n",
        "img = cv2.imread(\"HW/g3/rgb/1.jpg\")   # 2.param: RGB, Grayscale, Bináriskép\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "minVal, maxVal, _, _ = cv2.minMaxLoc(img_gray)    # hol vannak a szélsőértékek\n",
        "res=img_gray\n",
        "cv2.convertScaleAbs(img_gray,res,255/(maxVal-minVal),-minVal)  # affin -> kép*alfa + béta\n",
        "\n",
        "depth_img = cv2.imread(\"HW/g3/depth/1.png\")\n",
        "depth_img_gray = cv2.cvtColor(depth_img, cv2.COLOR_BGR2GRAY)\n",
        "minVal, maxVal, _, _ = cv2.minMaxLoc(depth_img_gray)    # hol vannak a szélsőértékek\n",
        "depth_res=depth_img_gray\n",
        "cv2.convertScaleAbs(depth_img_gray,depth_res,255/(maxVal-minVal),-minVal)  # affin -> kép*alfa + béta\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(res,cmap='gray')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(depth_res,cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL7_ps4RZ0rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all subfolders in a directory\n",
        "import os\n",
        "myFolderList = [f.path for f in os.scandir(path) if f.is_dir()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vj_xm0najIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all files with extension in a directory\n",
        "import glob\n",
        "import re\n",
        " \n",
        "def sorted_nicely( l ):\n",
        "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\"\n",
        "    convert = lambda text: int(text) if text.isdigit() else text\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
        "    return sorted(l, key = alphanum_key)\n",
        " \n",
        "names = sorted_nicely(glob.glob1(path, \"*.extension\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYQvzVjJaulE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class names\n",
        "classNames = ['traffic sign', 'vehicle', 'cactus']\n",
        "subclassNames = [\n",
        "    ['Bump', 'Bumpy road', 'Bus stop', 'Children', 'Crossing (blue)', 'Crossing (red)', 'Cyclists',\n",
        "     'Danger (other)', 'Dangerous left turn', 'Dangerous right turn', 'Give way', 'Go ahead', 'Go ahead or left',\n",
        "     'Go ahead or right', 'Go around either way', 'Go around left', 'Go around right', 'Intersection', 'Limit 100',\n",
        "     'Limit 120', 'Limit 20', 'Limit 30', 'Limit 50', 'Limit 60', 'Limit 70', 'Limit 80', 'Limit 80 over',\n",
        "     'Limit over', 'Main road', 'Main road over', 'Multiple dangerous turns', 'Narrow road (left)',\n",
        "     'Narrow road (right)', 'No entry', 'No entry (both directions)', 'No entry (truck)', 'No stopping', 'No takeover',\n",
        "     'No takeover (truck)', 'No takeover (truck) end', 'No takeover end', 'No waiting', 'One way road',\n",
        "     'Parking', 'Road works', 'Roundabout', 'Slippery road', 'Stop', 'Traffic light', 'Train crossing',\n",
        "     'Train crossing (no barrier)', 'Wild animals', 'X - Priority', 'X - Turn left', 'X - Turn right'],\n",
        "    ['SUV','truck','plane'],\n",
        "    ['happy','sad','angry','evil']\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gxeCxDPazgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the first images\n",
        "colors = [(0,0,255),(255,0,255),(0,255,0)]\n",
        "\n",
        "def drawBBs(BBs, img):\n",
        "    img = cv2.resize(img, (1280, 960))\n",
        "    for BB in BBs:\n",
        "        u = BB[0]*2\n",
        "        v = BB[1]*2\n",
        "        w = BB[2]*2\n",
        "        h = BB[3]*2\n",
        "        c = BB[4]\n",
        "        sc = BB[5]\n",
        "        x = BB[6]\n",
        "        y = BB[7]\n",
        "        z = BB[8]\n",
        "        s = (u - w // 2, v - h // 2)\n",
        "        e = (u + w // 2, v + h // 2)\n",
        "        cv2.rectangle(img, s, e, colors[c], 1)\n",
        "        tl = (s[0], s[1]+15)\n",
        "        bl = (s[0], e[1]-5)\n",
        "        cv2.putText(img,subclassNames[c][sc],tl,cv2.FONT_HERSHEY_COMPLEX_SMALL,0.75,colors[c])\n",
        "        coords = \"(%.2f, %.2f, %.2f)\" % (x,y,z)\n",
        "        cv2.putText(img,coords,bl,cv2.FONT_HERSHEY_COMPLEX_SMALL,0.65,colors[c])\n",
        "    \n",
        "    return img\n",
        "\n",
        "import pickle\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "#This way it doesn't try to open a window un the GUI - works in python notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Read images\n",
        "img = cv2.imread(\"HW/g1/rgb/1.jpg\")\n",
        "depth = cv2.imread(\"HW/g1/depth/1.png\", -1)\n",
        "\n",
        "# Read annotations\n",
        "file = open('HW/annotations.pickle','rb')\n",
        "annotations = pickle.load(file)\n",
        "\n",
        "# Visualization\n",
        "depth = depth / 5000.0\n",
        "img = drawBBs(annotations[\"HW/g1/rgb/1.jpg\"][\"objects\"], img)\n",
        "img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Figure with subplots\n",
        "plt.figure(figsize=(30,30))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img_rgb)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(depth,cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}